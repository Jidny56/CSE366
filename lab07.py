# -*- coding: utf-8 -*-
"""Copy of Lab07.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Em_IPdKAnSxrN88DxiWd_K2LQRnxOj51
"""

!pip install --upgrade pip setuptools wheel
!pip install grad-cam

"""Step 1: Setup Google Colab Environment"""



from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image

"""Step 2: Check GPU Availability"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")



"""Step 3: Download and Load Caltech-101 Dataset"""

from torchvision import transforms

# Define transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize images to 224x224 (standard for pre-trained models)
    transforms.ToTensor(),           # Convert images to PyTorch tensors
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values
])

# Load the Caltech101 dataset
dataset = datasets.Caltech101(root="./data", download=True, transform=transform)

"""Step 4: Split Dataset into Training, Validation, and Test"""

train_size = int(0.8 * len(dataset))
val_size = int(0.1 * len(dataset))
test_size = len(dataset) - train_size - val_size

train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
val_loader = DataLoader(val_data, batch_size=32)
test_loader = DataLoader(test_data, batch_size=32)

"""Step 5: Load Pretrained ResNet50 Model"""

model = models.resnet50(pretrained=True)
model.fc = nn.Linear(2048, 101)  # Adjust final layer for 101 classes
model = model.to(device)

"""Step 6: Define Loss Function and Optimizer"""

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

"""Step 7: Train the Model"""

transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3-channel RGB
    transforms.Resize((224, 224)),  # Resize images to 224x224
    transforms.ToTensor(),  # Convert images to PyTorch tensors
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values
])

dataset = datasets.Caltech101(root="./data", download=True, transform=transform)
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

epochs = 10
for epoch in range(epochs):
    model.train()
    running_loss = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    print(f"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}")

"""Step 8: Validate the Model"""

transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3-channel RGB
    transforms.Resize((224, 224)),  # Resize images to 224x224
    transforms.ToTensor(),  # Convert images to PyTorch tensors
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values
])

dataset = datasets.Caltech101(root="./data", download=True, transform=transform)

# Split into train and validation sets
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

model.eval()
correct, total = 0, 0
with torch.no_grad():
    for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

print(f"Validation Accuracy: {100 * correct / total:.2f}%")

"""Step 9: Evaluate on Test Data"""

transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3-channel RGB
    transforms.Resize((224, 224)),  # Resize images to 224x224
    transforms.ToTensor(),  # Convert images to PyTorch tensors
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values
])

test_dataset = datasets.Caltech101(root="./data", download=True, transform=transform)

# Create the DataLoader for the test dataset
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

y_pred, y_true = [], []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        y_pred.extend(preds.cpu().numpy())
        y_true.extend(labels.cpu().numpy())

print("Confusion Matrix:")
print(confusion_matrix(y_true, y_pred))

print("Classification Report:")
print(classification_report(y_true, y_pred))

"""Step 10: Apply Grad-CAM for Explainability"""

import matplotlib.pyplot as plt
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
import numpy as np

# Adjust based on the model architecture (e.g., ResNet)
target_layer = model.layer4[-1]  # Choose the appropriate layer

# Initialize Grad-CAM with the target layer as a list
cam = GradCAM(model=model, target_layers=[target_layer])

# Iterate over the first 5 images in the test dataset
for i, (images, labels) in enumerate(test_loader):
    if i >= 5:  # Stop after 5 images
        break

    # Get one test image
    image = images[0].unsqueeze(0).to(device)

    # Generate Grad-CAM visualization
    grayscale_cam = cam(input_tensor=image)

    # Normalize and convert the mask to uint8
    grayscale_cam = np.uint8(255 * grayscale_cam[0])  # Scale the values between 0 and 255
    grayscale_cam = np.squeeze(grayscale_cam)  # Remove the extra dimension

    # Convert the image from tensor to numpy and prepare for visualization
    image_np = image.cpu().squeeze().permute(1, 2, 0).numpy()
    cam_image = show_cam_on_image(image_np, grayscale_cam)

    # Display the image with Grad-CAM overlay
    plt.imshow(cam_image)
    plt.title(f"Grad-CAM Visualization {i+1}")
    plt.axis("off")
    plt.show()

print("Grad-CAM visualizations for 5 test images displayed.")

"""Step 11: Save and Export the Model"""

from google.colab import drive
drive.mount('/content/drive')

model_save_path = '/content/drive/MyDrive/AI lab 7/caltech101_resnet50.pth'
torch.save(model.state_dict(), model_save_path)
print(f"Model saved successfully at {model_save_path}")